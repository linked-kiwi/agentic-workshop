{"cells":[{"cell_type":"markdown","metadata":{"id":"HP4Awff7hwn3"},"source":["## PROTECTION USING LLM-GUARD\n","\n","LLM-Guard is a guardrail which we can use for a range of security checking on prompts being sent to an AI model, and responses being returned.  In this notebook we'll use it to stop sensitive information being sent out to Gemini.\n","The guardrail achieves this by redacting sensitive information and then recovering it once we get the response.\n","\n"]},{"cell_type":"markdown","source":["We'll start by suppressing warning messages.  "],"metadata":{"id":"6MFY34d_6gsI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"mEhby7Yw1wOy","executionInfo":{"status":"ok","timestamp":1738269735216,"user_tz":-780,"elapsed":674,"user":{"displayName":"Malcolm Shore","userId":"03653801920052420148"}}},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{"id":"Wzq5VMfO1wOz"},"source":["Next, we'll install the llm-guard library. It has a key dependency on a specific version of numpy, so we'll also install that first. We'll still see an error but we can ignore it for what we're doing in this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NCEmJvpxiLHp"},"outputs":[],"source":["%pip -q install numpy==1.25.1 llm-guard"]},{"cell_type":"markdown","metadata":{"id":"Lh0Aw__IiWZh"},"source":["We'll now look at an example of how we use llm-guard to scan our input.  Note we have our Google API key set in the Colab vault.  \n","\n","We won't use every input and output guardrail for our demonstration. We'll use the Anonymize/Deanonymize paired guardrails, and as examples we'll select three additional input and three additional output guardrails.  We'll also be using the llm-guard vault to store the sensitive data that we anonymize in order to recover it for deanonymization."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"stlzHArMidzs","executionInfo":{"status":"ok","timestamp":1738269954983,"user_tz":-780,"elapsed":24005,"user":{"displayName":"Malcolm Shore","userId":"03653801920052420148"}}},"outputs":[],"source":["import os\n","import google.generativeai as genai\n","from google.colab import userdata\n","from llm_guard import scan_output, scan_prompt\n","from llm_guard.input_scanners import Anonymize, PromptInjection, TokenLimit, Toxicity\n","from llm_guard.output_scanners import Deanonymize, NoRefusal, Relevance, Sensitive\n","from llm_guard.vault import Vault"]},{"cell_type":"markdown","metadata":{"id":"yV5BKJHi1wO0"},"source":["We can now set up a handle to run prompts through the Google AI API."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"z9I-P_t61wO0","executionInfo":{"status":"ok","timestamp":1738269967365,"user_tz":-780,"elapsed":2396,"user":{"displayName":"Malcolm Shore","userId":"03653801920052420148"}}},"outputs":[],"source":["genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"]},{"cell_type":"markdown","metadata":{"id":"jcMUNV-Bi7rg"},"source":["We'll set up a vault to use for managing the data we need to anonymize.  We'll load four input scanners and four output scanners.  This takes some time to run first time as it has to download scanning models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9y1qYDOGjB2s"},"outputs":[],"source":["vault = Vault()\n","input_scanners = [Anonymize(vault), Toxicity(), TokenLimit(), PromptInjection()]\n","output_scanners = [Deanonymize(vault), NoRefusal(), Relevance(), Sensitive()]"]},{"cell_type":"markdown","metadata":{"id":"wZBxaQ0CjT_0"},"source":["We'll now hard code a sensitive prompt and use the llm-guard scanner to check it.  We'll check whether we can run the query, and we'll display what the sanitized query looks like."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FP2jgo2hjdUq"},"outputs":[],"source":["prompt = f\"\"\"\n","Make an SQL insert statement to add a new user to our database. His name is John Doe and his email is test@test.com. His phone number is 555-123-4567.\n","His credit card number is 4567-8901-2345-6789 and he works in Test LLC.\n","\"\"\"\n","\n","sanitized_prompt, results_valid, results_score = scan_prompt(input_scanners, prompt)"]},{"cell_type":"markdown","source":["Let's display the sanitized prompt that we've generated."],"metadata":{"id":"AyxRn6U77kVT"}},{"cell_type":"code","source":["print(sanitized_prompt)"],"metadata":{"id":"l8Ys-OgM7oNP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B6Pc7UP0jxZX"},"source":["OK, we found an email address and redacted it. We also found a person element which is flagged as sensitive and redacted that.  A toxicity scann was run but did not find any toxic content. Note the phone numbers don't appear in the redacted prompt.\n","\n","We can now send the redacted prompt to Gemini and then display the response."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_HpE6-dj6yT"},"outputs":[],"source":["model = genai.GenerativeModel(\"gemini-1.5-flash\")\n","response = model.generate_content(sanitized_prompt)\n","print(response.text)"]},{"cell_type":"markdown","metadata":{"id":"47Q4get-kEGu"},"source":["So Gemini has removed the credit card data that was in the original query - it has its own built in guardrail for this.  \n","\n","We can now run the output scanner to recover the redacted text and check the output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S50CEFDukKdI"},"outputs":[],"source":["sanitized_response_text, results_valid, results_score = scan_output(\n","    output_scanners, sanitized_prompt, response.text\n",")"]},{"cell_type":"markdown","source":["Let's now see what the final result is from running our response through the output guardrails."],"metadata":{"id":"cJdiehg278Mt"}},{"cell_type":"code","source":["print(sanitized_response_text)"],"metadata":{"id":"qyoxeB6t8JV4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nfQgxg-41wO1"},"source":["OK, we've got our result and the originally redacted text has been added back in place of the redaction placeholders - other than the credit card data whuich was removed by Gemini. The warning from the guardrails is carried through, together with the SQL statement with the remaining sensitive data reconstituted into the output results.\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}