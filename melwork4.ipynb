{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## SAGE - Self Adaptive Goal-Oriented Execution Agent  \n",
        "SAGE is an advanced AI agent system based on the Self-Adaptive Goal-oriented Execution framework, using Googleâ€™s Gemini API. It defines 4 roles and uses its AI model to run these in a self-adapting cycle."
      ],
      "metadata": {
        "id": "vsKjP5LncYmh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by loading the libraries we'll need"
      ],
      "metadata": {
        "id": "jjlStQrycY8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, List, Any, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum"
      ],
      "metadata": {
        "id": "YpeY9sYBcdpy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now need to set up our wrap-around CSS function."
      ],
      "metadata": {
        "id": "VRbLG2ufOEHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "    <style>\n",
        "      pre {white-space: pre-wrap;}\n",
        "    </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "rZGGVU6WLBN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a set of task status codes which we use to set task status as the tasks run."
      ],
      "metadata": {
        "id": "jZ3pV0Xac717"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TaskStatus(Enum):\n",
        "   PENDING = \"pending\"\n",
        "   IN_PROGRESS = \"in_progress\"\n",
        "   COMPLETED = \"completed\"\n",
        "   FAILED = \"failed\""
      ],
      "metadata": {
        "id": "mWx1OC5tdCm1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the class of Task. We'll be generating tasks and running them to achieve our goal."
      ],
      "metadata": {
        "id": "_U2Z-0pcdSJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Task:\n",
        "   id: str\n",
        "   description: str\n",
        "   priority: int\n",
        "   status: TaskStatus = TaskStatus.PENDING\n",
        "   dependencies: List[str] = None\n",
        "   result: Optional[str] = None\n",
        "\n",
        "   def __post_init__(self):\n",
        "       if self.dependencies is None:\n",
        "           self.dependencies = []"
      ],
      "metadata": {
        "id": "tsWIO6ZydSoU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll now create our Agent as a class, and set up a number of model calls within that class which together provide agentic capability. We'll be using four functions each making a model call with a role-specific context:  \n",
        "- self_assess  \n",
        "- adaptive_plan  \n",
        "- execute_goal_oriented  \n",
        "- integrate_experience  \n",
        "  \n",
        "We'll be using the same model for each in this demonstration. We can run multiple iterations and retain memory between iterations. We'll set up some class-wide variables for that. We'll include tracking of tokens used to indicate the relative cost of agentic AI."
      ],
      "metadata": {
        "id": "9vkOw0_rLfUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGEAgent:\n",
        "   \"\"\"Self-Adaptive Goal-oriented Execution AI Agent\"\"\"\n",
        "\n",
        "   def __init__(self, api_key: str, model_name: str = \"gemini-2.0-flash\"):\n",
        "       self.client = genai.Client(api_key=api_key)\n",
        "       self.ground_tool = types.Tool(google_search=types.GoogleSearch())\n",
        "       self.ground_config  = types.GenerateContentConfig(tools=[self.ground_tool])\n",
        "       self.ground_model   = model_name\n",
        "       self.memory = []\n",
        "       self.tasks = {}\n",
        "       self.context = {}\n",
        "       self.augment = \"\"\n",
        "       self.tokens = 0\n",
        "       self.iteration_count = 0\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# We'll define the helper functions we need to support the SAGE approach.\n",
        "# There's a function to clear the response of any ticks or json prefixes\n",
        "#\n",
        "   def tidy(self,text) -> str:\n",
        "      if text.startswith('```'):\n",
        "          text = text.split('```')[1]\n",
        "          if text.startswith('json'):\n",
        "              text = text[4:]\n",
        "      text = text.strip()\n",
        "      return text\n",
        "\n",
        "# A function to check if we've met all dependencies\n",
        "   def _dependencies_met(self, task: Task) -> bool:\n",
        "       \"\"\"Check if task dependencies are satisfied\"\"\"\n",
        "       for dep_id in task.dependencies:\n",
        "           if dep_id not in self.tasks or self.tasks[dep_id].status != TaskStatus.COMPLETED:\n",
        "               return False\n",
        "       return True\n",
        "\n",
        "# A function to update the context based on task results.\n",
        "   def _update_context(self, results: List[Dict[str, Any]]):\n",
        "       \"\"\"Update agent context based on execution results\"\"\"\n",
        "       completed_tasks = [r for r in results if r[\"task\"][\"status\"] == \"completed\"]\n",
        "       self.context.update({\n",
        "           \"completed_tasks\": len(completed_tasks),\n",
        "           \"total_tasks\": len(self.tasks),\n",
        "           \"success_rate\": len(completed_tasks) / len(results) if results else 0,\n",
        "           \"last_update\": time.time()\n",
        "       })\n",
        "\n",
        "#--------------------------------------------------------------------------------------------------\n",
        "# **Self Assess** is the first of the four model-based functions. It reviews the context and\n",
        "# assesses our overall level of completeness based on task completion.  The first thing we do is to\n",
        "# set up an assessment prompt and pass it with our current context into the GenAI model requesting\n",
        "# a self-assessment. The function returns in JSON form a dictionary as defined.\n",
        "   def self_assess(self, goal: str, context: Dict[str, Any]) -> Dict[str, Any]:\n",
        "       \"\"\"S: Self-Assessment - Evaluate current state and capabilities\"\"\"\n",
        "\n",
        "       assessment_prompt = f\"\"\"\n",
        "       You are an AI agent conducting self-assessment to determine the progress you are\n",
        "       making in reaching the goal. Calculate the progress score by considering the\n",
        "       level of detail on each task completed, whether more detail can be added, and\n",
        "       whether more steps are recommended.\n",
        "       Respond ONLY with valid JSON, no additional text.\n",
        "       GOAL: {goal}\n",
        "       CONTEXT: {json.dumps(context, indent=2)}\n",
        "       TASKS_PROCESSED: {len(self.tasks)}\n",
        "       Provide assessment as JSON with these exact keys:\n",
        "       {{\n",
        "           \"progress_score\": <number 0-100>,\n",
        "           \"resources\": [\"list of available resources\"],\n",
        "           \"gaps\": [\"list of knowledge gaps\"],\n",
        "           \"risks\": [\"list of potential risks\"],\n",
        "           \"recommendations\": [\"list of next steps\"]\n",
        "       }}\n",
        "       \"\"\"\n",
        "\n",
        "       response = self.client.models.generate_content(\n",
        "           model=self.ground_model,\n",
        "           contents=assessment_prompt,\n",
        "           config=self.ground_config)\n",
        "       self.tokens = self.tokens + response.usage_metadata.total_token_count\n",
        "       try:\n",
        "           text = self.tidy(response.text.strip())\n",
        "           return json.loads(text)\n",
        "       except Exception as e:\n",
        "           print(f\"Assessment parsing error: {e}\")\n",
        "           return {\n",
        "               \"progress_score\": 25,\n",
        "               \"resources\": [\"AI capabilities\", \"Internet knowledge\"],\n",
        "               \"gaps\": [\"Specific domain expertise\", \"Real-time data\"],\n",
        "               \"risks\": [\"Information accuracy\", \"Scope complexity\"],\n",
        "               \"recommendations\": [\"Break down into smaller tasks\", \"Focus on research first\"]\n",
        "           }\n",
        "\n",
        "#------------------------------------------------------------------------------------------\n",
        "# **Adaptive_Plan** The second function is the adaptive planning which breaks down the goal into\n",
        "# 3-4 tasks per iteration. We call the GenAI model and get the response in JSON form, and then\n",
        "# extract the tasks into the tasks array.\n",
        "   def adaptive_plan(self, goal: str, assessment: Dict[str, Any]) -> List[Task]:\n",
        "       \"\"\"A: Adaptive Planning - Create dynamic, context-aware task decomposition\"\"\"\n",
        "\n",
        "       planning_prompt = f\"\"\"\n",
        "       You are an AI task planner. Respond ONLY with valid JSON array, no additional text.\n",
        "       MAIN_GOAL: {goal}\n",
        "       ASSESSMENT: {json.dumps(assessment, indent=2)}\n",
        "       Create 4-5 actionable tasks as JSON array:\n",
        "       [\n",
        "           {{\n",
        "               \"id\": \"task_1\",\n",
        "               \"description\": \"Clear, specific task description\",\n",
        "               \"priority\": 5,\n",
        "               \"dependencies\": []\n",
        "           }},\n",
        "           {{\n",
        "               \"id\": \"task_2\",\n",
        "               \"description\": \"Another specific task\",\n",
        "               \"priority\": 4,\n",
        "               \"dependencies\": [\"task_1\"]\n",
        "           }}\n",
        "       ]\n",
        "       Each task must have: id (string), description (string), priority (1-5), dependencies (array of strings)\n",
        "       \"\"\"\n",
        "\n",
        "       response = self.client.models.generate_content(\n",
        "           model=self.ground_model,\n",
        "           contents=planning_prompt,\n",
        "           config=self.ground_config)\n",
        "       self.tokens = self.tokens + response.usage_metadata.total_token_count\n",
        "       try:\n",
        "           text = self.tidy(response.text.strip())\n",
        "           task_data = json.loads(text)\n",
        "           tasks = []\n",
        "           for i, task_info in enumerate(task_data):\n",
        "               task = Task(\n",
        "                   id=task_info.get('id', f'task_{i+1}'),\n",
        "                   description=task_info.get('description', 'Undefined task'),\n",
        "                   priority=task_info.get('priority', 3),\n",
        "                   dependencies=task_info.get('dependencies', [])\n",
        "               )\n",
        "               tasks.append(task)\n",
        "           return tasks\n",
        "       except Exception as e:\n",
        "           print(f\"Planning parsing error: {e}\")\n",
        "           return [\n",
        "               Task(id=\"research_1\", description=\"Research sustainable urban gardening basics\", priority=5),\n",
        "               Task(id=\"research_2\", description=\"Identify space-efficient growing methods\", priority=4),\n",
        "               Task(id=\"compile_1\", description=\"Organize findings into structured guide\", priority=3, dependencies=[\"research_1\", \"research_2\"])\n",
        "           ]\n",
        "\n",
        "#-------------------------------------------------------------------------------------\n",
        "# **Goal Oriented Execution** The next function is used to executes a task based on the goal and\n",
        "# the current context. The AI model is directed to break the task into steps and execute\n",
        "# each step. The results are added to the augmentation information to be used to write\n",
        "# the report.\n",
        "   def execute_goal_oriented(self, task: Task) -> str:\n",
        "       \"\"\"G: Goal-oriented Execution - Execute specific task with focused attention\"\"\"\n",
        "\n",
        "       execution_prompt = f\"\"\"\n",
        "       GOAL-ORIENTED EXECUTION:\n",
        "       Task: {task.description}\n",
        "       Priority: {task.priority}\n",
        "       Context: {json.dumps(self.context, indent=2)}\n",
        "       Execute this task step-by-step:\n",
        "       1. Break down the task into concrete actions\n",
        "       2. Execute each action methodically\n",
        "       3. Validate results at each step\n",
        "       4. Provide comprehensive output\n",
        "       Focus on practical, actionable results. Be specific and thorough.\n",
        "       \"\"\"\n",
        "\n",
        "       response = self.client.models.generate_content(\n",
        "           model=self.ground_model,\n",
        "           contents=execution_prompt,\n",
        "           config=self.ground_config)\n",
        "       self.tokens = self.tokens + response.usage_metadata.total_token_count\n",
        "       return response.text.strip()\n",
        "\n",
        "#---------------------------------------------------------------------------------------\n",
        "# **Integrate_Experience** The final function calls a model to integrate the task and\n",
        "# the results of executing it with learnings from the current experience.\n",
        "   def integrate_experience(self, task: Task, result: str, success: bool) -> Dict[str, Any]:\n",
        "       \"\"\"E: Experience Integration - Learn from outcomes and update knowledge\"\"\"\n",
        "\n",
        "       integration_prompt = f\"\"\"\n",
        "       You are learning from task execution. Respond ONLY with valid JSON, no additional text.\n",
        "       TASK: {task.description}\n",
        "       RESULT: {result[:200]}...\n",
        "       SUCCESS: {success}\n",
        "       Provide learning insights as JSON:\n",
        "       {{\n",
        "           \"learnings\": [\"key insight 1\", \"key insight 2\"],\n",
        "           \"patterns\": [\"pattern observed 1\", \"pattern observed 2\"],\n",
        "           \"adjustments\": [\"adjustment for future 1\", \"adjustment for future 2\"],\n",
        "           \"confidence_boost\": <number -10 to 10>\n",
        "       }}\n",
        "       \"\"\"\n",
        "\n",
        "       response = self.client.models.generate_content(\n",
        "           model=self.ground_model,\n",
        "           contents=integration_prompt,\n",
        "           config=self.ground_config)\n",
        "       self.tokens = self.tokens + response.usage_metadata.total_token_count\n",
        "       try:\n",
        "           text = self.tidy(response.text.strip())\n",
        "           experience = json.loads(text)\n",
        "           experience['task_id'] = task.id\n",
        "           experience['timestamp'] = time.time()\n",
        "           self.memory.append(experience)\n",
        "           return experience\n",
        "       except Exception as e:\n",
        "           print(f\"Experience parsing error: {e}\")\n",
        "           experience = {\n",
        "               \"learnings\": [f\"Completed task: {task.description}\"],\n",
        "               \"patterns\": [\"Task execution follows planned approach\"],\n",
        "               \"adjustments\": [\"Continue systematic approach\"],\n",
        "               \"confidence_boost\": 5 if success else -2,\n",
        "               \"task_id\": task.id,\n",
        "               \"timestamp\": time.time()\n",
        "           }\n",
        "           self.memory.append(experience)\n",
        "           return experience\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# The sage_out function is used to generate the final report to satisfy the goal\n",
        "# based on the aggregated augmentation information, and using glm4's own built-in\n",
        "# web search capability.\n",
        "   def sage_out(self, goal: str):\n",
        "       \"\"\"Create the final report\"\"\"\n",
        "       print(f\" Creating Final Report\")\n",
        "\n",
        "       report_prompt = f\"\"\"\n",
        "       You are a Report Writer who can take RESEARCH information and write a well structured report to\n",
        "       meet the GOAL provided. Respond using an essay format report with detailed information for each\n",
        "       point covered in the research. Search the web to get additional details to flesh out the report\n",
        "       and provide examples for all key bullet points.\n",
        "       GOAL: {goal}\n",
        "       RESEARCH: {self.augment}\n",
        "       \"\"\"\n",
        "       response = self.client.models.generate_content(\n",
        "           model=self.ground_model,\n",
        "           contents=report_prompt,\n",
        "           config=self.ground_config)\n",
        "       self.tokens = self.tokens + response.usage_metadata.total_token_count\n",
        "       return response.text.strip()\n",
        "\n",
        "# The final routine controls the calls to the models, providing the agentic flow\n",
        "# through the agent.\n",
        "   def execute_sage_cycle(self, goal: str, max_iterations: int = 3) -> Dict[str, Any]:\n",
        "       \"\"\"Execute complete SAGE cycle for goal achievement\"\"\"\n",
        "       print(f\"SAGE analysis for goal: {goal}\")\n",
        "       results = {\"goal\": goal, \"iterations\": [], \"final_status\": \"unknown\"}\n",
        "\n",
        "       assessment = self.self_assess(goal, self.context)\n",
        "       for iteration in range(max_iterations):\n",
        "           self.iteration_count += 1\n",
        "           print(f\"\\nSAGE Iteration {iteration + 1}\")\n",
        "\n",
        "           tasks = self.adaptive_plan(goal, assessment)\n",
        "           print(f\" Adaptive Planning generated {len(tasks)} tasks\")\n",
        "\n",
        "           print(\" Goal-oriented Execution...\")\n",
        "           iteration_results = []\n",
        "\n",
        "           for task in sorted(tasks, key=lambda x: x.priority, reverse=True):\n",
        "               if self._dependencies_met(task):\n",
        "                   task.status = TaskStatus.IN_PROGRESS\n",
        "\n",
        "                   try:\n",
        "                       result = self.execute_goal_oriented(task)\n",
        "                       task.result = result\n",
        "                       self.augment = self.augment + result.strip()\n",
        "                       task.status = TaskStatus.COMPLETED\n",
        "                       success = True\n",
        "                       print(f\"   Completed: {task.description}\")\n",
        "                   except Exception as e:\n",
        "                       task.status = TaskStatus.FAILED\n",
        "                       task.result = f\"Error: {str(e)}\"\n",
        "                       success = False\n",
        "                       print(f\"   Failed: {task.description}\")\n",
        "\n",
        "                   print(\" Integrating learned experience...\")\n",
        "                   experience = self.integrate_experience(task, task.result, success)\n",
        "\n",
        "                   self.tasks[task.id] = task\n",
        "                   iteration_results.append({\n",
        "                       \"task\": asdict(task),\n",
        "                       \"experience\": experience\n",
        "                   })\n",
        "\n",
        "           self._update_context(iteration_results)\n",
        "\n",
        "           results[\"iterations\"].append({\n",
        "               \"iteration\": iteration + 1,\n",
        "               \"assessment\": assessment,\n",
        "               \"tasks_generated\": len(tasks),\n",
        "               \"tasks_completed\": len([r for r in iteration_results if r[\"task\"][\"status\"] == \"completed\"]),\n",
        "               \"results\": iteration_results\n",
        "           })\n",
        "\n",
        "           assessment = self.self_assess(goal, self.context)\n",
        "           print(f\" Self-Assessment Score: {assessment.get('progress_score', 0)}/100\")\n",
        "           if assessment.get('progress_score', 0) >= 90:\n",
        "               results[\"final_status\"] = \"achieved\"\n",
        "               print(f\"\\nSAGE goal achieved at a cost of {self.tokens} tokens!\")\n",
        "               break\n",
        "\n",
        "       if results[\"final_status\"] == \"unknown\":\n",
        "           results[\"final_status\"] = \"in_progress\"\n",
        "\n",
        "       print(f\"\\nSAGE Report Generation...\")\n",
        "       report = self.sage_out(goal)\n",
        "       with open(\"Sage_Report\",\"w\") as f:\n",
        "          f.write(report)\n",
        "\n",
        "       return results"
      ],
      "metadata": {
        "id": "dG8BUqNIMHwd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now set our goal and then call the SAGE controller routine from our mainline.\n"
      ],
      "metadata": {
        "id": "MPkod7LsUSzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "   API_KEY = userdata.get(\"GEMINI_API_KEY\")\n",
        "   agent = SAGEAgent(API_KEY, model_name=\"gemini-2.0-flash\")\n",
        "   goal = \"Research and create a comprehensive guide on astrophotography\"\n",
        "   print(\"\\n\" + \"=\"*50)\n",
        "   print(\" SAGE EXECUTION SUMMARY\")\n",
        "   print(\"=\"*50)\n",
        "   try:\n",
        "       results = agent.execute_sage_cycle(goal, max_iterations=4)\n",
        "   except Exception as e:\n",
        "       print(f\"Error encountered: {e}\")"
      ],
      "metadata": {
        "id": "raoFp8S4aF1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results data structure contains three elements: goal, iterations, and final_status. The information researched is in the iterations item which is one entry for each iteration carried out. Each iteration has five elements: iteration, assessment, tasks_generated, tasks_completed, and results. The results item holds results for each task with elements task and experience. The task item has six elements: id, description, priority, status, dependencies, and the result which we focus on."
      ],
      "metadata": {
        "id": "Rp7muHC9uQ_D"
      }
    }
  ]
}